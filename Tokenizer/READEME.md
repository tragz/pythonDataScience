
# Tokenizer
Tokenization of strings


## Installation

#### Add Virtual Environment
```bash
    python -m venv venv
    source venv/bin/activate
```

#### Install ntlk with pip

```bash
    pip install -U nltk
```
    
## Documentation

#### Why do we need to tokenize strings?
- break down complex text into manageable units
- present text in format easire to analyze or perfom operation
- specific linguistic task, part-of-speech tagging, syntatic parsing, NER
- NLP application and create structured training data

## Authors

- [@tragz](https://github.com/tragz)


## ðŸš€ About Me
I'm a full stack developer...


## Acknowledgements

 - [Explalined: Tokens  and Embeddings in LLMs](https://medium.com/the-research-nest/explained-tokens-and-embeddings-in-llms-69a16ba5db33)



 More on READEME
 - [Awesome Readme Templates](https://awesomeopensource.com/project/elangosundar/awesome-README-templates)
 - [Awesome README](https://github.com/matiassingers/awesome-readme)
 - [How to write a Good readme](https://bulldogjob.com/news/449-how-to-write-a-good-readme-for-your-github-project)


## Appendix

Any additional information goes here

